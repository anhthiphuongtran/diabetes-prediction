{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8X8xDwS6vgS"
   },
   "source": [
    "# About the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is about building logistics regression model to predict diabetes status in patients (positive or negative) based on their medical history and demographic information namely age, gender, body mass index (BMI), hypertension, heart disease, HbA1c level, and blood glucose level. This can be useful in an attempt to explore the relationships between various medical and demographic factors and the likelihood of developing diabetes as well as assisting healthcare professionals in identifying patients who may be at risk of developing diabetes and in developing personalized treatment plans.\n",
    "\n",
    "The dataset used in this project is downloaded from <a href=\"https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset?resource=download\">kaggle website</a>, consisting of 100,000 observations, each representing a patient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEGG4I6n60cM"
   },
   "source": [
    "# Importing Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D4b029YC7C-y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aa536pRY7Eq5"
   },
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4POXlqg47Ny3"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('diabetes_prediction_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has the shape of (100000, 8).\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dataset has the shape of {dataset.shape}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease    bmi  HbA1c_level  \\\n",
       "0  Female  80.0             0              1  25.19          6.6   \n",
       "1  Female  54.0             0              0  27.32          6.6   \n",
       "2    Male  28.0             0              0  27.32          5.7   \n",
       "3  Female  36.0             0              0  23.45          5.0   \n",
       "4    Male  76.0             1              1  20.14          4.8   \n",
       "\n",
       "   blood_glucose_level  diabetes  \n",
       "0                  140         0  \n",
       "1                   80         0  \n",
       "2                  158         0  \n",
       "3                  155         0  \n",
       "4                  155         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Missing values: {dataset.isna().values.any()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if there is any missing value in a column:\n",
      "gender                 False\n",
      "age                    False\n",
      "hypertension           False\n",
      "heart_disease          False\n",
      "bmi                    False\n",
      "HbA1c_level            False\n",
      "blood_glucose_level    False\n",
      "diabetes               False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(f\"Check if there is any missing value in a column:\\n{dataset.isna().any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated values: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicated values: {dataset.duplicated().values.any()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91313, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Logistics Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the set of features and the set of dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hhb-7rqjRZnt",
    "outputId": "272ee463-12e4-4126-d61c-1b0d0f5c29ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Female' 80.0 0 ... 25.19 6.6 140]\n",
      " ['Female' 54.0 0 ... 27.32 6.6 80]\n",
      " ['Male' 28.0 0 ... 27.32 5.7 158]\n",
      " ...\n",
      " ['Male' 66.0 0 ... 27.83 5.7 155]\n",
      " ['Female' 24.0 0 ... 35.42 4.0 100]\n",
      " ['Female' 57.0 0 ... 22.43 6.6 90]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fWREHrHTRnVe",
    "outputId": "2bf554a3-82b2-4f0e-fe5d-c799f1971b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6CXk5JfR4gu"
   },
   "source": [
    "## Encoding the Independent Variable\n",
    "\n",
    "Since the `gender` column includes categorical data, I will handle it with one-hot encoding. This creates new (binary) columns, indicating the presence of each possible value from the original data (here is `male` and `female`). One-hot encoding enables machine learning models to work with categorical data effectively while avoiding misinterpretation of ordinal relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4A_aNqU6RwDd"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the set of features (X) once again after encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 ... 25.19 6.6 140]\n",
      " [1.0 0.0 0.0 ... 27.32 6.6 80]\n",
      " [0.0 1.0 0.0 ... 27.32 5.7 158]\n",
      " ...\n",
      " [0.0 1.0 0.0 ... 27.83 5.7 155]\n",
      " [1.0 0.0 0.0 ... 35.42 4.0 100]\n",
      " [1.0 0.0 0.0 ... 22.43 6.6 90]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AnzJQCj7TLO"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set\n",
    "\n",
    "Train test split is a model validation procedure that allows us to simulate how a model would perform on new/unseen data. Here the Test set is split into 20% of actual data and the training set is split into 80% of the actual data.\n",
    "\n",
    "We will later train the model on the training set and test the model on the testing set and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WOQwyng57dp2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS1Q-n_A7iZ_"
   },
   "source": [
    "## Training the Logistic Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "9V-LgiUa78lX",
    "outputId": "c54bfd10-1427-46d9-e248-7e8e8d47b3a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0, max_iter=10000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cgD7EnB8Dnd"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1B4zQvOq8M7H"
   },
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26CHkZbs8Tu5"
   },
   "source": [
    "## Making the Confusion Matrix\n",
    "\n",
    "A confusion matrix is a performance evaluation tool in machine learning, representing the accuracy of a classification model. It displays the number of true positives, true negatives, false positives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5BN8qx6e8aNZ",
    "outputId": "6b623da0-450a-474f-fbd9-821354c7d096"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16470   160]\n",
      " [  606  1027]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix shows that when we test the performance of the established logistics regression model on the testing set, there are 16470 true positives, 1027 true negatives, 606 false positives and 160 false negatives. \n",
    "\n",
    "Based on the resulting confusion matrix, let's calculate the accuracy of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580572742703828"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(16470 + 1027) / (16470 + 1027 + 606 + 160) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMErnLnu8hmb"
   },
   "source": [
    "## Computing the accuracy with k-Fold Cross Validation\n",
    "\n",
    "I have just evaluated the model only once and I am not sure my good result is by luck or not. I want to evaluate the model multiple times so I can be more confident about the model design. Therefore, I will employ k-fold cross-validation. This approach divides the input dataset into k groups of samples of equal sizes, called folds. For each learning set, the prediction function uses k-1 folds and the remaining fold is used for test set.\n",
    "\n",
    "The result of a k-fold cross-validation run is summarized with the mean of accuracy scores. I also include a measure of the variance of accuracy scores, which is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "waJZi8fw8m_2",
    "outputId": "2aed34d7-6475-4c4e-85c0-7f2dc2f2235e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.68 %\n",
      "Standard Deviation: 0.21 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has been proved to perform very well with the mean of accuracies from k-fold cross validation reaching 95.68% and the associated standard deviation standing at only 0.21%."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
